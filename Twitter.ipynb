{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scweet.scweet import scrape\n",
    "from Scweet.user import get_user_information, get_users_following, get_users_followers\n",
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elonmusk'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = ['elonmusk', '@yassineaitjeddi', 'TahaAlamIdrissi',] \n",
    "         #'@Nabila_Gl', 'geceeekusuu', '@pabu232', '@av_ahmet', '@x_born_to_die_x']\n",
    "users[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгрузил пароли с аккаунта\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = \".env\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спарсили фолловеров Илона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling elonmusk following\n",
      "Found 25 following\n",
      "Found 49 following\n",
      "Found 67 following\n",
      "Found 93 following\n",
      "Found 122 following\n",
      "Found 130 following\n",
      "Found 130 following\n",
      "file saved in outputs/elon.jsonelonmusk_elonmusk_following.json\n"
     ]
    }
   ],
   "source": [
    "following = get_users_following(users=['elonmusk'], env=env_path, verbose=0, headless = False, wait=2, file_path='outputs/elon.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаю список фолловеров, чтобы второй раз не парсить (перезапускал ноутбук)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elonmusk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SpaceX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@lexfridman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BillyM2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Erdayastronaut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>@arxivblog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>@Neuro_Skeptic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>@physorg_com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>@TeslaRoadTrip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>@khanacademy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            elonmusk\n",
       "0            @SpaceX\n",
       "1        @lexfridman\n",
       "2             @Tesla\n",
       "3          @BillyM2k\n",
       "4    @Erdayastronaut\n",
       "..               ...\n",
       "125       @arxivblog\n",
       "126   @Neuro_Skeptic\n",
       "127     @physorg_com\n",
       "128   @TeslaRoadTrip\n",
       "129     @khanacademy\n",
       "\n",
       "[130 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon_following = pd.read_json('outputs/elon.json')\n",
    "\n",
    "elon_following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут я разбиваю на 10 одинаковых частей, чтобы парсить и сохранять частями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['@SpaceX',\n",
       "  '@lexfridman',\n",
       "  '@Tesla',\n",
       "  '@BillyM2k',\n",
       "  '@Erdayastronaut',\n",
       "  '@mayemusk',\n",
       "  '@dogecoin',\n",
       "  '@boringcompany',\n",
       "  '@joerogan',\n",
       "  '@KoguanLeo',\n",
       "  '@kimbal',\n",
       "  '@robinw',\n",
       "  '@TerribleMaps'],\n",
       " ['@dawallach',\n",
       "  '@OriolVinyalsML',\n",
       "  '@TrungTPhan',\n",
       "  '@dailystoic',\n",
       "  '@kcoleman',\n",
       "  '@Jason',\n",
       "  '@yoyoel',\n",
       "  '@TwitterBlue',\n",
       "  '@DavidSacks',\n",
       "  '@tegmark',\n",
       "  '@Twitter',\n",
       "  '@SciGuySpace',\n",
       "  '@ScienceMagazine'],\n",
       " ['@rustyrockets',\n",
       "  '@NASAWebb',\n",
       "  '@hiromichimizuno',\n",
       "  '@WalterIsaacson',\n",
       "  '@sama',\n",
       "  '@micsolana',\n",
       "  '@Dilbert_Daily',\n",
       "  '@andst7',\n",
       "  '@mtaibbi',\n",
       "  '@jgebbia',\n",
       "  '@neuralink',\n",
       "  '@Grimezsz',\n",
       "  '@EvaFoxU'],\n",
       " ['@planet',\n",
       "  '@OfficialPCMR',\n",
       "  '@universal_sci',\n",
       "  '@gunsnrosesgirl3',\n",
       "  '@moxie',\n",
       "  '@HGJart',\n",
       "  '@ilyasut',\n",
       "  '@EuropaClipper',\n",
       "  '@paraga',\n",
       "  '@TheBabylonBee',\n",
       "  '@Rainmaker1973',\n",
       "  '@inspiration4x',\n",
       "  '@CNSAWatcher'],\n",
       " ['@gigadgets_',\n",
       "  '@slashdot',\n",
       "  '@totalspace360',\n",
       "  '@redditSpacePorn',\n",
       "  '@rookisaacman',\n",
       "  '@TheMarsSociety',\n",
       "  '@dogecoin_devs',\n",
       "  '@karpathy',\n",
       "  '@Astro_Soichi',\n",
       "  '@PopMech',\n",
       "  '@PyTorch',\n",
       "  '@Nigel_Lockyer',\n",
       "  '@AstroVicGlover'],\n",
       " ['@Tesmanian_com',\n",
       "  '@machineIearning',\n",
       "  '@BBC_Future',\n",
       "  '@kanyewest',\n",
       "  '@Tesla_Asia',\n",
       "  '@ashleevance',\n",
       "  '@OpenAI',\n",
       "  '@ID_AA_Carmack',\n",
       "  '@slatestarcodex',\n",
       "  '@jack',\n",
       "  '@TalulahRiley',\n",
       "  '@MKBHD',\n",
       "  '@MachinePix'],\n",
       " ['@NASASpaceflight',\n",
       "  '@wintonARK',\n",
       "  '@TashaARK',\n",
       "  '@archillect',\n",
       "  '@skorusARK',\n",
       "  '@wonderofscience',\n",
       "  '@SpaceForceCSO',\n",
       "  '@SpaceForceDoD',\n",
       "  '@Liv_Boeree',\n",
       "  '@shivon',\n",
       "  '@neiltyson',\n",
       "  '@wlopwangling',\n",
       "  '@Brian_J_Berger'],\n",
       " ['@CathieDWood',\n",
       "  '@4thFromOurStar',\n",
       "  '@BBCScienceNews',\n",
       "  '@TheStoicEmperor',\n",
       "  '@HardcoreHistory',\n",
       "  '@Jon_Favreau',\n",
       "  '@yousuck2020',\n",
       "  '@pmarca',\n",
       "  '@engineers_feed',\n",
       "  '@bbccomedy',\n",
       "  '@levine',\n",
       "  '@nichegamer',\n",
       "  '@ToscaMusk'],\n",
       " ['@lisajoynolan',\n",
       "  '@BBCBreaking',\n",
       "  '@geekwire',\n",
       "  '@SwiftOnSecurity',\n",
       "  '@cgpgrey',\n",
       "  '@westcoastbill',\n",
       "  '@fermatslibrary',\n",
       "  '@RickandMorty',\n",
       "  '@NASAJPL',\n",
       "  '@Space_Station',\n",
       "  '@WorldAndScience',\n",
       "  '@Hyperloop',\n",
       "  '@medical_xpress'],\n",
       " ['@SouthPark',\n",
       "  '@HistoryInPics',\n",
       "  '@platobooktour',\n",
       "  '@NASA',\n",
       "  '@developonline',\n",
       "  '@TheHackersNews',\n",
       "  '@xkcdComic',\n",
       "  '@waitbutwhy',\n",
       "  '@arxivblog',\n",
       "  '@Neuro_Skeptic',\n",
       "  '@physorg_com',\n",
       "  '@TeslaRoadTrip',\n",
       "  '@khanacademy']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "following_list = elon_following.values.flatten().tolist()\n",
    "prep_list = list(split(following_list, 10))\n",
    "prep_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две главные строчки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping on headless mode.\n",
      "Crawling @lisajoynolan following\n",
      "Found 17 following\n",
      "Found 46 following\n",
      "Found 63 following\n",
      "Found 82 following\n",
      "Found 100 following\n",
      "Crawling @BBCBreaking following\n",
      "Found 3 following\n",
      "Found 3 following\n",
      "Crawling @geekwire following\n",
      "Found 16 following\n",
      "Found 45 following\n",
      "Found 62 following\n",
      "Found 81 following\n",
      "Found 100 following\n",
      "Crawling @SwiftOnSecurity following\n",
      "Found 16 following\n",
      "Found 44 following\n",
      "Found 65 following\n",
      "Found 84 following\n",
      "Found 100 following\n",
      "Crawling @cgpgrey following\n",
      "Found 17 following\n",
      "Found 46 following\n",
      "Found 66 following\n",
      "Found 86 following\n",
      "Found 100 following\n",
      "Crawling @westcoastbill following\n",
      "Found 17 following\n",
      "Found 44 following\n",
      "Found 60 following\n",
      "Found 76 following\n",
      "Found 95 following\n",
      "Found 100 following\n",
      "Crawling @fermatslibrary following\n",
      "Found 4 following\n",
      "Found 4 following\n",
      "Crawling @RickandMorty following\n",
      "Found 17 following\n",
      "Found 40 following\n",
      "Found 62 following\n",
      "Found 82 following\n",
      "Found 100 following\n",
      "Crawling @NASAJPL following\n",
      "Found 16 following\n",
      "Found 44 following\n",
      "Found 62 following\n",
      "Found 80 following\n",
      "Found 95 following\n",
      "Found 100 following\n",
      "Crawling @Space_Station following\n",
      "Found 16 following\n",
      "Found 46 following\n",
      "Found 67 following\n",
      "Found 84 following\n",
      "Found 100 following\n",
      "Crawling @WorldAndScience following\n",
      "Found 16 following\n",
      "Found 27 following\n",
      "Found 27 following\n",
      "Crawling @Hyperloop following\n",
      "Found 17 following\n",
      "Found 36 following\n",
      "Found 57 following\n",
      "Found 75 following\n",
      "Found 82 following\n",
      "Found 82 following\n",
      "Crawling @medical_xpress following\n",
      "Found 16 following\n",
      "Found 21 following\n",
      "file saved in outputs/@lisajoynolan_@medical_xpress_following.json\n",
      "Scraping on headless mode.\n",
      "Crawling @SouthPark following\n",
      "Found 18 following\n",
      "Found 36 following\n",
      "Found 57 following\n",
      "Found 76 following\n",
      "Found 96 following\n",
      "Found 100 following\n",
      "Crawling @HistoryInPics following\n",
      "Found 17 following\n",
      "Found 39 following\n",
      "Found 56 following\n",
      "Found 76 following\n",
      "Found 96 following\n",
      "Found 100 following\n",
      "Crawling @platobooktour following\n",
      "Found 16 following\n",
      "Found 44 following\n",
      "Found 60 following\n",
      "Found 81 following\n",
      "Found 100 following\n",
      "Crawling @NASA following\n",
      "Found 16 following\n",
      "Found 44 following\n",
      "Found 64 following\n",
      "Found 84 following\n",
      "Found 100 following\n",
      "Crawling @developonline following\n",
      "Found 15 following\n",
      "Found 41 following\n",
      "Found 62 following\n",
      "Found 82 following\n",
      "Found 100 following\n",
      "Crawling @TheHackersNews following\n",
      "Found 16 following\n",
      "Found 44 following\n",
      "Found 64 following\n",
      "Found 86 following\n",
      "Found 100 following\n",
      "Crawling @xkcdComic following\n",
      "Found 1 following\n",
      "Found 1 following\n",
      "Crawling @waitbutwhy following\n",
      "Found 18 following\n",
      "Found 47 following\n",
      "Found 64 following\n",
      "Found 83 following\n",
      "Found 100 following\n",
      "Crawling @arxivblog following\n",
      "Found 0 following\n",
      "Crawling @Neuro_Skeptic following\n",
      "Found 15 following\n",
      "Found 42 following\n",
      "Found 62 following\n",
      "Found 81 following\n",
      "Found 99 following\n",
      "Found 100 following\n",
      "Crawling @physorg_com following\n",
      "Found 16 following\n",
      "Found 37 following\n",
      "Found 56 following\n",
      "Found 75 following\n",
      "Found 95 following\n",
      "Found 100 following\n",
      "Crawling @TeslaRoadTrip following\n",
      "Found 18 following\n",
      "Found 39 following\n",
      "Found 60 following\n",
      "Found 76 following\n",
      "Found 76 following\n",
      "Crawling @khanacademy following\n",
      "Found 16 following\n",
      "Found 46 following\n",
      "Found 64 following\n",
      "Found 85 following\n",
      "Found 100 following\n",
      "file saved in outputs/@SouthPark_@khanacademy_following.json\n"
     ]
    }
   ],
   "source": [
    "for i in prep_list:\n",
    "    get_users_following(users=i, env=env_path, verbose=0, headless = True, wait=3, limit=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соберём все полученные части в формате жсон в человеческий формат csv, чтобы работать с кайфом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = pd.read_json('outputs/1.json')\n",
    "with open('outputs/1.json') as data:    \n",
    "    f1 = json.load(data) \n",
    "with open('outputs/2.json') as data:    \n",
    "    f2 = json.load(data)  \n",
    "with open('outputs/3.json') as data:    \n",
    "    f3 = json.load(data)  \n",
    "with open('outputs/4.json') as data:    \n",
    "    f4 = json.load(data)  \n",
    "with open('outputs/5.json') as data:    \n",
    "    f5 = json.load(data)  \n",
    "with open('outputs/6.json') as data:    \n",
    "    f6 = json.load(data)  \n",
    "with open('outputs/7.json') as data:    \n",
    "    f7 = json.load(data)  \n",
    "with open('outputs/8.json') as data:    \n",
    "    f8 = json.load(data)  \n",
    "with open('outputs/9.json') as data:    \n",
    "    f9 = json.load(data)  \n",
    "with open('outputs/10.json') as data:    \n",
    "    f10 = json.load(data)  \n",
    "\n",
    "\n",
    "full_f = {**f1, **f2,**f3, **f4,**f5, **f6,**f7, **f8,**f9, **f10}\n",
    "dictlist = [x for x in full_f.items()]\n",
    "\n",
    "for i in range(len(full_f.keys())):\n",
    "    t = len(dictlist[i][1])\n",
    "    dictlist[i][1].extend([0] * (100 - t))\n",
    "    #print(dictlist[i][1])\n",
    "\n",
    "df = pd.DataFrame(dictlist)\n",
    "df.to_csv('outputs/df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
